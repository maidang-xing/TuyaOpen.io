"use strict";(self.webpackChunktuyaopen_io_website=self.webpackChunktuyaopen_io_website||[]).push([["1761"],{283:function(e,t,n){n.r(t),n.d(t,{metadata:()=>i,default:()=>h,frontMatter:()=>s,contentTitle:()=>a,toc:()=>c,assets:()=>l});var i=JSON.parse('{"id":"projects/2025-08-01-auraflow","title":"Auraflow","description":"Project Overview","source":"@site/docs/projects/2025-08-01-auraflow.md","sourceDirName":"projects","slug":"/projects/2025-08-01-auraflow","permalink":"/docs/projects/2025-08-01-auraflow","draft":false,"unlisted":false,"editUrl":"https://github.com/Tuya-Community/TuyaOpen.io/edit/master/docs/projects/2025-08-01-auraflow.md","tags":[],"version":"current","frontMatter":{"title":"Auraflow","date":"2025-08-01T00:00:00.000Z"}}'),r=n(4848),o=n(8453);let s={title:"Auraflow",date:new Date("2025-08-01T00:00:00.000Z")},a="Auraflow",l={},c=[{value:"Project Overview",id:"project-overview",level:2},{value:"Features",id:"features",level:2},{value:"Technology Stack",id:"technology-stack",level:2},{value:"Quick Start",id:"quick-start",level:2},{value:"Repository Link",id:"repository-link",level:2},{value:"Copyright &amp; License",id:"copyright--license",level:2}];function d(e){let t={a:"a",h1:"h1",h2:"h2",header:"header",li:"li",ol:"ol",p:"p",strong:"strong",ul:"ul",...(0,o.R)(),...e.components},{BackToProjects:n}=t;return n||function(e,t){throw Error("Expected "+(t?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("BackToProjects",!0),(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n,{}),"\n",(0,r.jsx)(t.header,{children:(0,r.jsx)(t.h1,{id:"auraflow",children:"Auraflow"})}),"\n",(0,r.jsx)(t.h2,{id:"project-overview",children:"Project Overview"}),"\n",(0,r.jsx)(t.p,{children:"An intelligent companion tomato timer robot designed for users who easily fall into deep focus, helping them rest scientifically through personalized intervention mechanisms. This project exemplifies TuyaOpen's vision of making AI accessible to everyone, demonstrating how the framework enables developers to create sophisticated AI-powered devices that understand and respond to human behavior patterns through cloud-based AI processing."}),"\n",(0,r.jsx)(t.p,{children:"The system supports two trigger modes: 1) Timed reminders based on preset duration (user customizable); 2) Active intervention when focus decline is detected in real-time (such as delivering drinks), guiding rest in a non-intrusive way. TuyaOpen's cloud-based multi-modal AI capabilities make it possible to integrate brain-computer interfaces, computer vision, and robotic control into a seamless, intelligent system that adapts to individual user needs through cloud processing."}),"\n",(0,r.jsx)("p",{align:"center",children:(0,r.jsx)("img",{src:"https://images.tuyacn.com/fe-static/docs/img/74f40f1e-8650-4e59-9593-837255081cc9.jpg",alt:"Auraflow Project Screenshot",style:{width:"80%",borderRadius:"12px",boxShadow:"0 2px 16px rgba(0,0,0,0.08)"}})}),"\n",(0,r.jsx)(t.h2,{id:"features",children:"Features"}),"\n",(0,r.jsxs)(t.ul,{children:["\n",(0,r.jsx)(t.li,{children:"Tangible guardian (robotic arm physical interaction)"}),"\n",(0,r.jsx)(t.li,{children:"Precise insight (brain-computer interface real-time monitoring)"}),"\n",(0,r.jsx)(t.li,{children:"Active intervention (threshold trigger mechanism)"}),"\n",(0,r.jsx)(t.li,{children:"Empowerment growth (focus training)"}),"\n",(0,r.jsx)(t.li,{children:"Personalized optimization (adjustable thresholds and duration)"}),"\n",(0,r.jsx)(t.li,{children:"Small GUI screen for user interaction"}),"\n",(0,r.jsx)(t.li,{children:"Non-intrusive physical reminders"}),"\n"]}),"\n",(0,r.jsx)(t.h2,{id:"technology-stack",children:"Technology Stack"}),"\n",(0,r.jsxs)(t.ul,{children:["\n",(0,r.jsxs)(t.li,{children:[(0,r.jsx)(t.strong,{children:"TuyaOpen Framework"}),": Complete AIoT platform enabling seamless integration of complex systems with cloud AI"]}),"\n",(0,r.jsxs)(t.li,{children:[(0,r.jsx)(t.strong,{children:"Robotics"}),": Robotic arm trajectory planning, Lerobot SO100 setup and control"]}),"\n",(0,r.jsxs)(t.li,{children:[(0,r.jsx)(t.strong,{children:"AI Processing"}),": Cloud-based YOLO object detection through TuyaOpen"]}),"\n",(0,r.jsxs)(t.li,{children:[(0,r.jsx)(t.strong,{children:"Interface"}),": Frontend development, brain-computer interface visualization with cloud connectivity"]}),"\n",(0,r.jsxs)(t.li,{children:[(0,r.jsx)(t.strong,{children:"Hardware"}),": Small GUI screen, robotic arm system with cloud AI integration"]}),"\n",(0,r.jsxs)(t.li,{children:[(0,r.jsx)(t.strong,{children:"Software"}),": Focus monitoring algorithms, intervention mechanisms powered by cloud AI"]}),"\n"]}),"\n",(0,r.jsx)(t.h2,{id:"quick-start",children:"Quick Start"}),"\n",(0,r.jsxs)(t.ol,{children:["\n",(0,r.jsx)(t.li,{children:"Set up the robotic arm system (Lerobot SO100)"}),"\n",(0,r.jsx)(t.li,{children:"Configure the brain-computer interface"}),"\n",(0,r.jsx)(t.li,{children:"Implement YOLO object detection"}),"\n",(0,r.jsx)(t.li,{children:"Set up the GUI interface"}),"\n",(0,r.jsx)(t.li,{children:"Configure focus monitoring algorithms"}),"\n",(0,r.jsx)(t.li,{children:"Set intervention thresholds and timing"}),"\n",(0,r.jsx)(t.li,{children:"Test the complete system integration"}),"\n"]}),"\n",(0,r.jsx)(t.h2,{id:"repository-link",children:"Repository Link"}),"\n",(0,r.jsx)("p",{align:"center",children:(0,r.jsx)("a",{href:"https://github.com/boshenzh/echo-robot/tree/GUI/apps/echome_smart",target:"_blank",className:"button button--primary",style:{fontSize:"1.15rem",padding:"14px 2.5em",borderRadius:"16px",background:"linear-gradient(90deg, #4f8cff 0%, #38b2ac 100%)",color:"#fff",boxShadow:"0 4px 24px rgba(79,140,255,0.18), 0 1.5px 6px rgba(56,178,172,0.10)",border:"none",fontWeight:"bold",letterSpacing:"0.04em",transition:"transform 0.15s, box-shadow 0.15s",display:"inline-block"},children:(0,r.jsx)(t.p,{children:"\u{1F680} Go to Project Repository"})})}),"\n",(0,r.jsx)(t.h2,{id:"copyright--license",children:"Copyright & License"}),"\n",(0,r.jsxs)(t.p,{children:["This project was developed as part of ",(0,r.jsx)(t.a,{href:"https://adventure-x.org/zh",children:"Adventure X 2025 Hangzhou Hackathon"}),". The project and all its components are owned by the participating team members and contest participants. All rights reserved."]})]})}function h(e={}){let{wrapper:t}={...(0,o.R)(),...e.components};return t?(0,r.jsx)(t,{...e,children:(0,r.jsx)(d,{...e})}):d(e)}},8453:function(e,t,n){n.d(t,{R:()=>s,x:()=>a});var i=n(6540);let r={},o=i.createContext(r);function s(e){let t=i.useContext(o);return i.useMemo(function(){return"function"==typeof e?e(t):{...t,...e}},[t,e])}function a(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:s(e.components),i.createElement(o.Provider,{value:t},e.children)}}}]);